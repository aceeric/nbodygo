package runner

/*
#define _GNU_SOURCE
#include <sched.h>
#include <pthread.h>

void lock_thread(int cpuid) {
        pthread_t tid;
        cpu_set_t cpuset;

        tid = pthread_self();
        CPU_ZERO(&cpuset);
        CPU_SET(cpuid, &cpuset);
    pthread_setaffinity_np(tid, sizeof(cpu_set_t), &cpuset);
}
*/
import "C"

import (
	"nbodygo/cmd/body"
	"nbodygo/cmd/cmap"
	"runtime"
	"sync"
	"time"
)

// contains a body - to compute force for - and a map of all other bodies in the simulation
type Computation struct {
	body *body.SimBody
	bodyQueue *cmap.ConcurrentMap
}

// defines a function that computes force on a body from other bodies in the simulation
//type ComputeFunc func(*Computation)
type ComputeFunc func(*body.SimBody, *cmap.ConcurrentMap)

// Intended to be run as a goroutine. Pins itself to a CPU and runs indefinitely until
// it is signalled to stop. Receives work to perform on a channel in the Worker param
func bodyComputer(worker *Worker, wg *sync.WaitGroup, computeFunc ComputeFunc) {
	runtime.LockOSThread()
	C.lock_thread(C.int(worker.cpu))
	if computeFunc == nil {
        computeFunc = DefaultComputeFunc
    }
    millis := int64(0)
	for {
		select {
		case <-worker.killChan:
			//fmt.Printf("worker shutdown. id: %v, invocations: %v, millis: %v, latency: %v\n", worker.id,
			//	worker.invocations, millis, float32(millis) / float32(worker.invocations))
			return
		case c := <-worker.computation:
			start := time.Now()
            computeFunc(c.body, worker.bodyQueue)
            //if c.body != nil {}
            worker.invocations++
            wg.Done()
			millis += time.Now().Sub(start).Milliseconds()
		default:
			time.Sleep(time.Nanosecond)
		}
	}
}

// A dummy default compute function
func DefaultComputeFunc(*body.SimBody, *cmap.ConcurrentMap) {
    time.Sleep(time.Millisecond * 50)
}

// defines that things needed by a body computer
type Worker struct {
    id          uint
	killChan    chan bool
	computation chan Computation
	cpu         uint
	invocations uint
	bodyQueue *cmap.ConcurrentMap // TEST
}

// defines a worker pool
type WorkPool struct {
    wrkIdx      uint
    cpus        uint
	workers     []*Worker
	wg          sync.WaitGroup
    submissions int64
    millis      int64
}

// creates a new worker pool with the passed number of threads, and the passed computation
// function. Spins up 'threads' number of goroutines running the  passed function
func NewWorkPool(threads int, computeFunc ComputeFunc) *WorkPool {
	wp := WorkPool{
        wrkIdx:  0,
        cpus:    uint(runtime.NumCPU()),
		workers: []*Worker{},
		wg:      sync.WaitGroup{},
    }
	for i := 0; i < threads; i++ {
		w := Worker{
            id:          uint(i),
			killChan:    make(chan bool),
			computation: make(chan Computation, 200), // TODO DETERMINE VALUE
			cpu:         uint(i) % wp.cpus,
            invocations: 0,
		}
		wp.workers = append(wp.workers, &w)
		if computeFunc == nil {
            computeFunc = DefaultComputeFunc
        }
		go bodyComputer(&w, &wp.wg, computeFunc)
	}
	return &wp
}

// signals all goroutines in the worker pool to stop. (They may not stop right away if they are performing
// a computation)
func (wp *WorkPool) StopAll() {
	for _, worker := range wp.workers {
		worker.killChan <- true
	}
	//fmt.Printf("submissions: %v, millis: %v, latency: %v\n", wp.submissions, wp.millis,
	//	float32(wp.millis) / float32(wp.submissions))
}

// future
func (wp *WorkPool) setThreads(threads int) {
	// TODO handle increase / decrease in threads balancing across cpus
}

// creates a Computation from the passed args, and submits it round-robin to the pool. The design
// assumption is each computation will take approximately the same time to complete and so there doesn't
// need to be anything fancy with regard to finding the least utilized goroutine and assigning the
// work to that routine
func (wp *WorkPool) submit(b *body.SimBody, bodyQueue *cmap.ConcurrentMap) {
    worker := wp.workers[wp.wrkIdx % uint(len(wp.workers))]
    wp.wg.Add(1)
    // computation channel is buffered so we get concurrency as well as a limited number of threads
    // with thread-cpu affinity
	start := time.Now()
	worker.bodyQueue = bodyQueue
    worker.computation<- Computation{
        body:      b,
        bodyQueue: bodyQueue,
    }
	wp.millis += time.Now().Sub(start).Milliseconds()
	wp.submissions++
    wp.wrkIdx++
}

// waits for one work to complete
func (wp *WorkPool) take() {
	wp.wg.Wait()
}
